{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbouras13/phold/blob/main/run_pharokka_and_phold_and_phynteny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGd2GEI3N-02"
      },
      "source": [
        "#Pharokka + Phold + Phynteny\n",
        "\n",
        "[pharokka](https://github.com/gbouras13/pharokka) is a rapid standardised annotation tool for bacteriophage genomes and metagenomes. You can read more about pharokka in the [documentation](https://pharokka.readthedocs.io/).\n",
        "\n",
        "[phold](https://github.com/gbouras13/phold) is a sensitive annotation tool for bacteriophage genomes and metagenomes using protein structural homology. You can read more about phold in the [documentation](https://phold.readthedocs.io/).\n",
        "\n",
        "phold uses the [ProstT5](https://github.com/mheinzinger/ProstT5) protein language model to translate protein amino acid sequences to the 3Di token alphabet used by [Foldseek](https://github.com/steineggerlab/foldseek). Foldseek is then used to search these against a database of 803k protein structures mostly predicted using [Colabfold](https://github.com/sokrypton/ColabFold).\n",
        "\n",
        "[phyntney](https://github.com/susiegriggo/Phynteny) uses a long-short term memory model trained on phage synteny (the conserved gene order across phages) to assign hypothetical phage proteins to a PHROG category.\n",
        "\n",
        "**NOTE: Phynteny will only work if your phage has fewer than 120 predicted genes**\n",
        "\n",
        "**If this is the case for your phage(s), you should just skip running Phynteny (Cells 5+6)**\n",
        "\n",
        "The tools are best run sequentially, as Pharokka conducts extra annotation steps like tRNA, tmRNA, CRISPR and INPHARED searches that Phold lacks (for now at least). Pharokka will also (rarely) annotate CDS that Phold can miss. Phynteny can then help annotate remaining hypothetical proteins with a PHROG category.\n",
        "\n",
        "* **Before you start, please make sure you change the runtime to T4 GPU (or any other kind of GPU if you have $$$), otherwise Phold won't be installed properly**\n",
        "* To do this, go to the top toolbar, then to Runtime -> Change runtime type -> Hardware accelerator\n",
        "\n",
        "* To run the cells, press the play button on the left side\n",
        "* Cells 1 and 2 install pharokka and phold and download the databases/models.\n",
        "* Once they have been run, you can re-run Cell 3 (to run Pharokka), Cell 4 (to run Phold) and Cell 5+6 (to install and run Phynteny) as many times as you would like\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ii39RG8eOZUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9192c95-a2a8-4be6-c52e-d8569779931a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python version 3.10\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.1)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting traitlets (from matplotlib-inline)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Installing collected packages: traitlets, matplotlib-inline\n",
            "Successfully installed matplotlib-inline-0.1.7 traitlets-5.14.3\n",
            "Usage: phold [OPTIONS] COMMAND [ARGS]...\n",
            "\n",
            "Options:\n",
            "  -h, --help     Show this message and exit.\n",
            "  -V, --version  Show the version and exit.\n",
            "\n",
            "Commands:\n",
            "  citation          Print the citation(s) for this tool\n",
            "  compare           Runs Foldseek vs phold db\n",
            "  createdb          Creates foldseek DB from AA FASTA and 3Di FASTA input...\n",
            "  install           Installs ProstT5 model and phold database\n",
            "  plot              Creates Phold Circular Genome Plots\n",
            "  predict           Uses ProstT5 to predict 3Di tokens - GPU recommended\n",
            "  proteins-compare  Runs Foldseek vs phold db on proteins input\n",
            "  proteins-predict  Runs ProstT5 on a multiFASTA input - GPU recommended\n",
            "  remote            Uses Foldseek API to run ProstT5 then Foldseek locally\n",
            "  run               phold predict then comapare all in one - GPU recommended\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Install pharokka and phold\n",
        "\n",
        "#@markdown This cell installs pharokka and phold. It will take a few minutes. Please be patient\n",
        "\n",
        "%%bash\n",
        "\n",
        "set -e\n",
        "\n",
        "PYTHON_VERSION=\"3.10\"\n",
        "PHAROKKA_VERSION=\"1.7.5\"\n",
        "PHOLD_VERSION=\"0.2.0\"\n",
        "\n",
        "echo \"python version ${PYTHON_VERSION}\"\n",
        "\n",
        "if [ ! -f CONDA_READY ]; then\n",
        "  echo \"installing python\"\n",
        "  wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "  bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "  rm Miniconda3-latest-Linux-x86_64.sh\n",
        "  conda config --set auto_update_conda false\n",
        "  touch CONDA_READY\n",
        "fi\n",
        "\n",
        "if [ ! -f PHAROKKA_PHOLD_READY ]; then\n",
        "  echo \"installing pharokka and phold\"\n",
        "  conda install -y -c conda-forge -c bioconda pip pharokka==${PHAROKKA_VERSION} python=${PYTHON_VERSION} phold==${PHOLD_VERSION} pytorch=*=cuda*\n",
        "  pip install --upgrade matplotlib matplotlib-inline\n",
        "  phold -h\n",
        "  touch PHAROKKA_PHOLD_READY\n",
        "fi\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfltpbZ_QLfZ",
        "outputId": "813773ce-727e-4a81-a091-1b21e7d3509e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pharokka database. This will take a few minutes. Please be patient :)\n",
            "Downloading phold database. This will take a few minutes. Please be patient :)\n",
            "CPU times: user 2.05 s, sys: 314 ms, total: 2.36 s\n",
            "Wall time: 12min 59s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#@title 2. Download pharokka phold databases\n",
        "\n",
        "#@markdown This cell downloads the pharokka then the phold database. It will take some time (5-10 minutes probably). Please be patient.\n",
        "\n",
        "\n",
        "%%time\n",
        "import os\n",
        "print(\"Downloading pharokka database. This will take a few minutes. Please be patient :)\")\n",
        "os.system(\"install_databases.py -o pharokka_db\")\n",
        "print(\"Downloading phold database. This will take a few minutes. Please be patient :)\")\n",
        "os.system(\"phold install -d phold_db\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjdpu6R-Kig9",
        "outputId": "2a445171-4456-496a-e198-cbe6507cf70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input file SAOMS1.fasta exists\n",
            "Running pharokka\n",
            "pharokka completed successfully.\n",
            "Your output is in output_pharokka.\n",
            "Zipping the output directory so you can download it all in one go.\n",
            "Output directory has been zipped to output_pharokka.zip\n",
            "CPU times: user 144 ms, sys: 23.5 ms, total: 168 ms\n",
            "Wall time: 41.5 s\n"
          ]
        }
      ],
      "source": [
        "#@title 3. Run Pharokka\n",
        "\n",
        "#@markdown First, upload your phage(s) as a nucleotide input FASTA file\n",
        "\n",
        "#@markdown Click on the folder icon to the left and use the file upload button.\n",
        "\n",
        "#@markdown Once it is uploaded, write the file name in the INPUT_FILE field on the right.\n",
        "\n",
        "#@markdown Then provide a directory for pharokka's output using PHAROKKA_OUT_DIR.\n",
        "#@markdown The default is 'output_pharokka'.\n",
        "\n",
        "#@markdown Then type in a gene prediction tool for pharokka.\n",
        "#@markdown Please choose either 'phanotate', 'prodigal', or 'prodigal-gv'.\n",
        "\n",
        "#@markdown You can also provide a prefix for your output files with PHAROKKA_PREFIX.\n",
        "#@markdown If you provide nothing it will default to 'pharokka'.\n",
        "\n",
        "#@markdown You can also provide a locus tag for your output files.\n",
        "#@markdown If you provide nothing it will generate a random locus tag.\n",
        "\n",
        "#@markdown You can click FAST to turn off --fast.\n",
        "#@markdown By default it is True so that Pharokka runs faster in the Colab environment.\n",
        "\n",
        "#@markdown You can click META to turn on --meta if you have multiple phages in your input.\n",
        "\n",
        "#@markdown You can click META_HMM to turn on --meta_hmm.\n",
        "\n",
        "#@markdown You can click FORCE to overwrite the output directory.\n",
        "#@markdown This may be useful if your earlier pharokka run has crashed for whatever reason.\n",
        "\n",
        "#@markdown The results of Pharokka will be in the folder icon on the left hand panel.\n",
        "#@markdown Additionally, it will be zipped so you can download the whole directory.\n",
        "\n",
        "#@markdown The file to download is PHAROKKA_OUT_DIR.zip, where PHAROKKA_OUT_DIR is what you provided\n",
        "\n",
        "#@markdown If you do not see the output directory,\n",
        "#@markdown refresh the window by either clicking the folder with the refresh icon below \"Files\"\n",
        "#@markdown or double click and select \"Refresh\".\n",
        "\n",
        "\n",
        "%%time\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import zipfile\n",
        "INPUT_FILE = 'SAOMS1.fasta' #@param {type:\"string\"}\n",
        "\n",
        "if os.path.exists(INPUT_FILE):\n",
        "    print(f\"Input file {INPUT_FILE} exists\")\n",
        "else:\n",
        "    print(f\"Error: File {INPUT_FILE} does not exist\")\n",
        "    print(f\"Please check the spelling and that you have uploaded it correctly\")\n",
        "    sys.exit(1)\n",
        "\n",
        "PHAROKKA_OUT_DIR = 'output_pharokka'  #@param {type:\"string\"}\n",
        "GENE_PREDICTOR = 'phanotate'  #@param {type:\"string\"}\n",
        "allowed_gene_predictors = ['phanotate', 'prodigal', 'prodigal-gv']\n",
        "# Check if the input parameter is valid\n",
        "if GENE_PREDICTOR.lower() not in allowed_gene_predictors:\n",
        "    raise ValueError(\"Invalid GENE_PREDICTOR. Please choose from: 'phanotate', 'prodigal', 'prodigal-gv'.\")\n",
        "\n",
        "PHAROKKA_PREFIX = 'pharokka'  #@param {type:\"string\"}\n",
        "LOCUS_TAG = 'Default'  #@param {type:\"string\"}\n",
        "FAST = True  #@param {type:\"boolean\"}\n",
        "META = False  #@param {type:\"boolean\"}\n",
        "META_HMM = False  #@param {type:\"boolean\"}\n",
        "FORCE = True  #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Construct the command\n",
        "command = f\"pharokka.py -d pharokka_db -i {INPUT_FILE} -t 4 -o {PHAROKKA_OUT_DIR} -p {PHAROKKA_PREFIX} -l {LOCUS_TAG} -g {GENE_PREDICTOR}\"\n",
        "\n",
        "if FORCE is True:\n",
        "  command = f\"{command} -f\"\n",
        "\n",
        "if FAST is True:\n",
        "  command = f\"{command} --fast\"\n",
        "\n",
        "if META is True:\n",
        "  command = f\"{command} -m\"\n",
        "\n",
        "if META_HMM is True:\n",
        "  command = f\"{command} --meta_hmm\"\n",
        "\n",
        "# Execute the command\n",
        "try:\n",
        "    print(\"Running pharokka\")\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "    print(\"pharokka completed successfully.\")\n",
        "    print(f\"Your output is in {PHAROKKA_OUT_DIR}.\")\n",
        "    print(f\"Zipping the output directory so you can download it all in one go.\")\n",
        "\n",
        "    zip_filename = f\"{PHAROKKA_OUT_DIR}.zip\"\n",
        "\n",
        "    # Zip the contents of the output directory\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(PHAROKKA_OUT_DIR):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), PHAROKKA_OUT_DIR))\n",
        "    print(f\"Output directory has been zipped to {zip_filename}\")\n",
        "\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QfjP3q-Q04f",
        "outputId": "7deb5c37-1094-43f0-de67-668ec67fe4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running phold\n",
            "phold completed successfully.\n",
            "Your output is in output_phold.\n",
            "Zipping the output directory so you can download it all in one go.\n",
            "Output directory has been zipped to output_phold.zip\n",
            "CPU times: user 629 ms, sys: 104 ms, total: 733 ms\n",
            "Wall time: 3min 20s\n"
          ]
        }
      ],
      "source": [
        "#@title 4. Run phold\n",
        "\n",
        "#@markdown This cell will run phold on the output of cell 3's Pharokka run\n",
        "\n",
        "#@markdown You do not need to provide any further input files\n",
        "\n",
        "#@markdown You can now provide a directory for phold's output with PHOLD_OUT_DIR.\n",
        "#@markdown The default is 'output_phold'.\n",
        "\n",
        "#@markdown You can also provide a prefix for your output files with PHOLD_PREFIX.\n",
        "#@markdown If you provide nothing it will default to 'phold'.\n",
        "\n",
        "#@markdown You can click FORCE to overwrite the output directory with .\n",
        "#@markdown This may be useful if your earlier phold run has crashed for whatever reason.\n",
        "\n",
        "#@markdown If your input has multiple phages, you can click SEPARATE.\n",
        "#@markdown This will output separate GenBank files in the output directory.\n",
        "\n",
        "#@markdown The results of Phold will be in the folder icon on the left hand panel.\n",
        "#@markdown Additionally, it will be zipped so you can download the whole directory.\n",
        "\n",
        "#@markdown The file to download is PHOLD_OUT_DIR.zip, where PHOLD_OUT_DIR is what you provided\n",
        "\n",
        "#@markdown If you do not see the output directory,\n",
        "#@markdown refresh the window by either clicking the folder with the refresh icon below \"Files\"\n",
        "#@markdown or double click and select \"Refresh\".\n",
        "\n",
        "\n",
        "%%time\n",
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "\n",
        "# phold input is pharokka output\n",
        "PHOLD_INPUT = f\"{PHAROKKA_OUT_DIR}/{PHAROKKA_PREFIX}.gbk\"\n",
        "PHOLD_OUT_DIR = 'output_phold'  #@param {type:\"string\"}\n",
        "PHOLD_PREFIX = 'phold'  #@param {type:\"string\"}\n",
        "FORCE = True  #@param {type:\"boolean\"}\n",
        "SEPARATE = False  #@param {type:\"boolean\"}\n",
        "\n",
        "# Construct the command\n",
        "command = f\"phold run -i {PHOLD_INPUT} -t 4 -o {PHOLD_OUT_DIR} -p {PHOLD_PREFIX} -d phold_db\"\n",
        "\n",
        "if FORCE is True:\n",
        "  command = f\"{command} -f\"\n",
        "if SEPARATE is True:\n",
        "  command = f\"{command} --separate\"\n",
        "\n",
        "\n",
        "# Execute the command\n",
        "try:\n",
        "    print(\"Running phold\")\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "    print(\"phold completed successfully.\")\n",
        "    print(f\"Your output is in {PHOLD_OUT_DIR}.\")\n",
        "    print(f\"Zipping the output directory so you can download it all in one go.\")\n",
        "\n",
        "    zip_filename = f\"{PHOLD_OUT_DIR}.zip\"\n",
        "\n",
        "    # Zip the contents of the output directory\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(PHOLD_OUT_DIR):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), PHOLD_OUT_DIR))\n",
        "    print(f\"Output directory has been zipped to {zip_filename}\")\n",
        "\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Install phynteny\n",
        "\n",
        "#@markdown This cell installs phynteny and downloads the models. It will take a few minutes. Please be patient\n",
        "%%bash\n",
        "PHYNTENY_VERSION=\"0.1.13\"\n",
        "NUMPY_VERSION=\"1.26.4\"\n",
        "\n",
        "if [ ! -f PHYNTENY_READY ]; then\n",
        "  echo \"installing phynteny\"\n",
        "  pip install phynteny==${PHYNTENY_VERSION} numpy==${NUMPY_VERSION}\n",
        "  echo \"Downloading phynteny models\"\n",
        "  install_models -o phynteny_models\n",
        "  touch PHYNTENY_READY\n",
        "fi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eUYA415PNRX",
        "outputId": "6cb0d59a-25dd-4375-bce0-f6c011e95fc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing phynteny\n",
            "Collecting phynteny==0.1.13\n",
            "  Downloading phynteny-0.1.13-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.10/site-packages (from phynteny==0.1.13) (1.81)\n",
            "Collecting scikit-learn<=1.2.2 (from phynteny==0.1.13)\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from phynteny==0.1.13) (2.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from phynteny==0.1.13) (8.1.8)\n",
            "Collecting joblib (from phynteny==0.1.13)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/site-packages (from phynteny==0.1.13) (0.7.2)\n",
            "Collecting tensorflow==2.9.1 (from phynteny==0.1.13)\n",
            "  Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: alive-progress>=3.0.1 in /usr/local/lib/python3.10/site-packages (from phynteny==0.1.13) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/site-packages (from phynteny==0.1.13) (2.32.3)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.9.1->phynteny==0.1.13) (3.13.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorflow==2.9.1->phynteny==0.1.13) (24.2)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow==2.9.1->phynteny==0.1.13) (75.8.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.9.1->phynteny==0.1.13) (1.17.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/site-packages (from tensorflow==2.9.1->phynteny==0.1.13) (4.12.2)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: about_time==4.2.1 in /usr/local/lib/python3.10/site-packages (from alive-progress>=3.0.1->phynteny==0.1.13) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in /usr/local/lib/python3.10/site-packages (from alive-progress>=3.0.1->phynteny==0.1.13) (0.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.25.1->phynteny==0.1.13) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.25.1->phynteny==0.1.13) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.25.1->phynteny==0.1.13) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.25.1->phynteny==0.1.13) (2025.1.31)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/site-packages (from scikit-learn<=1.2.2->phynteny==0.1.13) (1.15.2)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn<=1.2.2->phynteny==0.1.13)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->phynteny==0.1.13) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->phynteny==0.1.13) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->phynteny==0.1.13) (2025.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.9.1->phynteny==0.1.13) (0.45.1)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13) (3.0.2)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->phynteny==0.1.13)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading phynteny-0.1.13-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 19.6 MB/s eta 0:00:00\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 157.8 MB/s eta 0:00:00\n",
            "Downloading tensorflow-2.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 511.7/511.7 MB 52.2 MB/s eta 0:00:00\n",
            "Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 94.7 MB/s eta 0:00:00\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 85.5 MB/s eta 0:00:00\n",
            "Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 56.5 MB/s eta 0:00:00\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.5/24.5 MB 96.0 MB/s eta 0:00:00\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 39.5 MB/s eta 0:00:00\n",
            "Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 39.1 MB/s eta 0:00:00\n",
            "Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 63.6 MB/s eta 0:00:00\n",
            "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 76.7 MB/s eta 0:00:00\n",
            "Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 34.3 MB/s eta 0:00:00\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: tensorboard-plugin-wit, libclang, keras, flatbuffers, wrapt, werkzeug, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, numpy, markdown, joblib, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, keras-preprocessing, scikit-learn, google-auth, google-auth-oauthlib, tensorboard, tensorflow, phynteny\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.5.2 flatbuffers-1.12 gast-0.4.0 google-auth-2.38.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.70.0 joblib-1.4.2 keras-2.9.0 keras-preprocessing-1.1.2 libclang-18.1.1 markdown-3.7 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.4.0 phynteny-0.1.13 protobuf-3.19.6 pyasn1-0.6.1 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 scikit-learn-1.2.2 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 threadpoolctl-3.5.0 werkzeug-3.1.3 wrapt-1.17.2\n",
            "Downloading phynteny models\n",
            "Downloading Phynteny models to phynteny_models\n",
            "Phynteny models are missing.\n",
            "Some models are missing.\n",
            "Downloading Phynteny Models from https://zenodo.org/record/8198288/files/phynteny_models_v0.1.11.tar.gz.\n",
            "path\n",
            "https://zenodo.org/record/8198288/files/phynteny_models_v0.1.11.tar.gz\n",
            "|████████████████████████████████████████| 381.6M/381.6M [100%] in 2:08.4 (2.97M/s) \n",
            "Phynteny Models tarball download OK: 364c1eab8cda872a8757c1187a5c2b53\n",
            "Extracting Phynteny Models tarball: file=phynteny_models/phynteny_models_v0.1.11.tar.gz, output=phynteny_models\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BlPLP3vlhWYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e5cfe0-7ca1-474d-f6f8-6bbf4f4a9f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running phynteny\n",
            "phynteny completed successfully.\n",
            "Your output is in output_phynteny.\n",
            "Zipping the output directory so you can download it all in one go.\n",
            "Output directory has been zipped to output_phynteny.zip\n",
            "CPU times: user 172 ms, sys: 21 ms, total: 193 ms\n",
            "Wall time: 44 s\n"
          ]
        }
      ],
      "source": [
        "#@title 6. Run Phynteny\n",
        "\n",
        "#@markdown This cell will run phynteny on the output of cell 4's Phold run to predict the function of remaining hypothetical proteins\n",
        "\n",
        "#@markdown You do not need to provide any further input files\n",
        "\n",
        "#@markdown You can now provide a directory for phynteny's output with PHYNTENY_OUT_DIR.\n",
        "#@markdown The default is 'output_phynteny'.\n",
        "\n",
        "#@markdown You can click FORCE to overwrite the output directory with .\n",
        "#@markdown This may be useful if your phynteny run has crashed for whatever reason.\n",
        "\n",
        "#@markdown The results of Phynteny will be in the folder icon on the left hand panel.\n",
        "#@markdown Additionally, it will be zipped so you can download the whole directory.\n",
        "\n",
        "#@markdown The file to download is PHYNTENY_OUT_DIR.zip, where PHYNTENY_OUT_DIR is what you provided\n",
        "\n",
        "#@markdown If you do not see the output directory,\n",
        "#@markdown refresh the window by either clicking the folder with the refresh icon below \"Files\"\n",
        "#@markdown or double click and select \"Refresh\".\n",
        "\n",
        "\n",
        "%%time\n",
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "\n",
        "# phynteny input is pharokka output\n",
        "PHYNTENY_INPUT = f\"{PHOLD_OUT_DIR}/{PHOLD_PREFIX}.gbk\"\n",
        "PHYNTENY_OUT_DIR = 'output_phynteny'  #@param {type:\"string\"}\n",
        "FORCE = False  #@param {type:\"boolean\"}\n",
        "\n",
        "# Construct the command\n",
        "command = f\"phynteny {PHYNTENY_INPUT} -m phynteny_models -o {PHYNTENY_OUT_DIR}\"\n",
        "\n",
        "if FORCE is True:\n",
        "  command = f\"{command} -f\"\n",
        "\n",
        "\n",
        "# Execute the command\n",
        "try:\n",
        "    print(\"Running phynteny\")\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "    print(\"phynteny completed successfully.\")\n",
        "    print(f\"Your output is in {PHYNTENY_OUT_DIR}.\")\n",
        "    print(f\"Zipping the output directory so you can download it all in one go.\")\n",
        "\n",
        "    zip_filename = f\"{PHYNTENY_OUT_DIR}.zip\"\n",
        "\n",
        "    # Zip the contents of the output directory\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(PHYNTENY_OUT_DIR):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), PHYNTENY_OUT_DIR))\n",
        "    print(f\"Output directory has been zipped to {zip_filename}\")\n",
        "\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMz6NVdLFZ7D1sQ3KDiFlhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}